{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0583359",
   "metadata": {},
   "source": [
    "# Fmrate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050d077e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_pipeline\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneural_network\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLPRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import uproot as ur\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.utils import train_val_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c431346",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ae8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"../data/fmrate_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769ebc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cb914",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ddc53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_df[[\"unix_time\", \"fe_cosmic\"]] # .drop(columns=[f\"rate[{i}]\" for i in range(12)])\n",
    "y = data_df[[f\"rate[{i}]\" for i in range(12)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d4b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf0c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y,\n",
    "                                                                      val_size=0.2,\n",
    "                                                                      test_size=0.2,\n",
    "                                                                      random_state=42,\n",
    "                                                                      shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "[el.shape for el in [X_train, X_val, X_test, y_train, y_val, y_test]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c741e",
   "metadata": {},
   "source": [
    "**We're not allowed to use the test set to make any decision !!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f45647",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling\n",
    "- https://youtu.be/juEOOQntrd0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1769cfd4",
   "metadata": {},
   "source": [
    "## Basic Fully Connected NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MLPRegressor(hidden_layer_sizes=[100, 100], random_state=42, max_iter=500)\n",
    "pipe = make_pipeline(StandardScaler(), estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f903c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train.drop(columns=[\"unix_time\"]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipe.predict(X_val.drop(columns=[\"unix_time\"]))\n",
    "pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ced005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae70954f",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let's only look at `rate[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a758dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "argsort = np.argsort(X_val[\"unix_time\"])[::-1]\n",
    "sorted_time_val = X_val[\"unix_time\"][argsort]\n",
    "sorted_y_val_r0 = y_val.loc[:, \"rate[0]\"][argsort]\n",
    "sorted_val_r0 = pred[:, 0][argsort]\n",
    "\n",
    "fig_val_prediction_rate_0, ax = plt.subplots()\n",
    "ax.plot(sorted_time_val, sorted_y_val_r0, '-g', linewidth=0.1)\n",
    "ax.plot(sorted_time_val, sorted_val_r0, '-r', linewidth=0.1)\n",
    "ax.set_xlabel(\"Tunix [s]\")\n",
    "ax.set_ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "ax.set_title(\"Light curve of Rate[0]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5efc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_n = 1000\n",
    "high_n = 1500\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, (low_n, high_n) in enumerate([(1000, 1500), (2000, 2500),\n",
    "                                   (10000, 10500), (12000, 12500)]):\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_y_val_r0[low_n:high_n], '-g', linewidth=0.5)\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_val_r0[low_n:high_n], '-r', linewidth=0.5)\n",
    "    axs[i//2, i%2].set_xlabel(\"Tunix [s]\")\n",
    "    axs[i//2, i%2].set_ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "    axs[i//2, i%2].set_title(f\"Light curve Rate[0]: l={low_n}, h={high_n}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_n = 1000\n",
    "high_n = 1500\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, (low_n, high_n) in enumerate([(1000, 1200), (2000, 2200),\n",
    "                                   (10000, 10200), (12000, 12200)]):\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_y_val_r0[low_n:high_n], '-g', linewidth=0.5)\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_val_r0[low_n:high_n], '-r', linewidth=0.5)\n",
    "    axs[i//2, i%2].set_xlabel(\"Tunix [s]\")\n",
    "    axs[i//2, i%2].set_ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "    axs[i//2, i%2].set_title(f\"Light curve Rate[0]: l={low_n}, h={high_n}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mlp = pipe[\"mlpregressor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aebc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(fitted_mlp.loss_), np.std(sorted_y_val_r0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12048153",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train_loss_per_epoch, ax = plt.subplots()\n",
    "\n",
    "ax.plot(fitted_mlp.loss_curve_)\n",
    "ax.set_title(\"Training loss per epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff822b3f",
   "metadata": {},
   "source": [
    "The loss is still quiet huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_mlp.coefs_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8350c20",
   "metadata": {},
   "source": [
    "**TODO: try compare it with linear regression only using `fe_cosmic`. Also show validation loss for each epoch !**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ee60e",
   "metadata": {},
   "source": [
    "### Residual plot\n",
    "**Warning: we're gonna use the whole dataset, careful about data leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f1d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the whole X.. just to observe the residuals\n",
    "pred_X_nn = pipe.predict(X.drop(columns=[\"unix_time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(X, y, pred_X, show=True, title=\"Light curve of Rate[0]: Prediction using whole dataset\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(X[\"unix_time\"], y.loc[:, \"rate[0]\"], '-g', linewidth=0.1)\n",
    "    ax.plot(X[\"unix_time\"], pred_X[:, 0], '-r', linewidth=0.1)\n",
    "    ax.set_xlabel(\"Tunix [s]\")\n",
    "    ax.set_ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "    ax.set_title(title)\n",
    "    if show: plt.show()\n",
    "    return fig\n",
    "\n",
    "fig_dataset_prediction_rate_0 = plot_pred(X, y, pred_X_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.03\n",
    "rect_residuals = [left, bottom, width, height]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_axes(rect_residuals)\n",
    "ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "\n",
    "ax.plot(X[\"unix_time\"], y.loc[:, \"rate[0]\"]-pred_X_nn[:, 0], '-r', linewidth=0.1)\n",
    "ax.set_xlabel(\"Tunix [s]\")\n",
    "ax.set_ylabel(\"Residual for Rate[0]\")  # Nb. photons per second (averaged over each bin)\n",
    "ax.set_title(\"Residual plot for Rate[0]\")\n",
    "\n",
    "\n",
    "ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "ax_histy.set_title(\"Histogram\")\n",
    "ax_histy.set_xlabel(\"Count\")\n",
    "\n",
    "\n",
    "_ = ax_histy.hist(y.loc[:, \"rate[0]\"]-pred_X_nn[:, 0], bins=100, orientation='horizontal', alpha=0.5, zorder=np.inf)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0e16b",
   "metadata": {},
   "source": [
    "**TODO: try compare it with linear regression only using `fe_cosmic`. Also show validation loss for each epoch !**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_pull(X, y, pred_X, show=True, \n",
    "              title=\"Pull plot for Rate[0]\", \n",
    "              title_hist=\"Normalized Histogram (Density)\"):\n",
    "    left, width = 0.1, 0.65\n",
    "    bottom, height = 0.1, 0.65\n",
    "    spacing = 0.03\n",
    "    rect_residuals = [left, bottom, width, height]\n",
    "    rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "\n",
    "    ax = fig.add_axes(rect_residuals)\n",
    "    ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "\n",
    "    tmp = (y.loc[:, \"rate[0]\"]-pred_X[:, 0])/np.sqrt(y.loc[:, \"rate[0]\"])\n",
    "    mask = ~np.isclose(y.loc[:, \"rate[0]\"], 0)\n",
    "\n",
    "    ax.plot(X[\"unix_time\"][mask], tmp[mask], '-r', linewidth=0.1)\n",
    "    ax.set_xlabel(\"Tunix [s]\")\n",
    "    ax.set_ylabel(\"Pull for Rate[0]\")  # Nb. photons per second  (averaged over each bin)\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "\n",
    "    ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "    ax_histy.set_title(title_hist)\n",
    "\n",
    "\n",
    "    # _ = ax_histy.hist(tmp[mask], bins=100, orientation='horizontal', alpha=0.5, zorder=np.inf)\n",
    "    _ = sns.histplot(data=tmp[mask].to_frame(\"rate[0]\"),\n",
    "                     y=\"rate[0]\",\n",
    "                     stat=\"density\",\n",
    "                     ax=ax_histy)\n",
    "    mean = np.mean(tmp[mask])\n",
    "    std = np.std(tmp[mask])\n",
    "    xs = np.linspace(tmp[mask].min(), tmp[mask].max(), 255)\n",
    "    f = lambda x: 1/np.sqrt(2*np.pi*std**2)*np.exp(-(x-mean)**2/(2*std**2))\n",
    "    _ = ax_histy.plot(f(xs), xs, zorder=np.inf, color=\"m\", linewidth=1, linestyle=\"--\")\n",
    "\n",
    "    if show: plt.show()\n",
    "    return fig\n",
    "\n",
    "fig_dataset_pull_plot_rate_0 = plot_pull(X, y, pred_X_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba012939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.scale import FuncScale\n",
    "\n",
    "\n",
    "def plot(data, mean, std, transform=\"sqrt\", show=True, title=\"Normalized Histogram (Density)\"):\n",
    "    f = lambda x, mean, std: 1/np.sqrt(2*np.pi*std**2)*np.exp(-(x-mean)**2/(2*std**2))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "#     _ = sns.histplot(data=data,\n",
    "#                      x=\"rate[0]\",\n",
    "#                      stat=\"density\",\n",
    "#                      ax=ax)\n",
    "    ax.hist(data, bins=500, alpha=0.5, density=True)\n",
    "\n",
    "    xs = np.linspace(data.min(), data.max(), 255)\n",
    "    ax.plot(xs, f(xs, mean, std), zorder=np.inf, color=\"m\", linewidth=1, linestyle=\"--\")\n",
    "    ax.plot([-5*std, -5*std], [0, f(xs, mean, std).max()/36], 'r', label=r\"$-5\\sigma$\")\n",
    "    ax.plot([5*std, 5*std], [0, f(xs, mean, std).max()/36], 'g', label=r\"$+5\\sigma$\")\n",
    "    ax.legend()\n",
    "    if transform == \"sqrt\":\n",
    "        ax.set_yscale(FuncScale(0, (lambda x: np.sqrt(x), lambda x: np.power(x, 2))))\n",
    "        if title is not None: ax.set_title(\"Sqrt Normalized Histogram (Density)\")\n",
    "    else:\n",
    "        ax.set_title(title)\n",
    "    if show: plt.show()\n",
    "    return fig\n",
    "\n",
    "tmp = (y.loc[:, \"rate[0]\"]-pred_X_nn[:, 0])/np.sqrt(y.loc[:, \"rate[0]\"])\n",
    "mask = ~np.isclose(y.loc[:, \"rate[0]\"], 0)\n",
    "mean = np.mean(tmp[mask])\n",
    "std = np.std(tmp[mask])\n",
    "    \n",
    "_ = plot(tmp[mask].to_frame(\"rate[0]\"), mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e0b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "5*std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ef40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_std(data):\n",
    "    low = -np.inf\n",
    "    high = np.inf\n",
    "    prev_std = np.inf\n",
    "    std = np.std(data)\n",
    "    mean = np.mean(data)\n",
    "    \n",
    "    while ~np.isclose(prev_std, std):\n",
    "        # Update interval\n",
    "        low = -3*std + mean\n",
    "        high = 3*std + mean\n",
    "        \n",
    "        prev_std = std\n",
    "        std = np.std(data[(data>low) & (data<high)])\n",
    "        print(mean, std, low, high)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mean, new_std = find_std(tmp[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "std, new_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6842f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot(tmp[mask].to_frame(\"rate[0]\"), mean, new_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dataset_reduced_pull_hist_rate_0 = plot(tmp[mask].to_frame(\"rate[0]\"), mean, new_std, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aee192",
   "metadata": {},
   "source": [
    "**Weights and biases logs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.sklearn import plot_learning_curve\n",
    "\n",
    "model = pipe\n",
    "model_params = model.get_params()\n",
    "\n",
    "# Wandb:\n",
    "with wandb.init(project='POLAR-background-prediction', config=model_params):\n",
    "    wandb.config.update({\"val_size\": 0.2,\n",
    "                         \"test_size\": 0.2,\n",
    "                         \"val_len\": X_val.shape[0],\n",
    "                         \"test_len\": X_test.shape[0],\n",
    "                         \"train_len\": X_train.shape[0],\n",
    "                         \"random_state\": 42,\n",
    "                         \"shuffle_data\": True})\n",
    "\n",
    "    wandb.log({\"validation/prediction-rate-0\": fig_val_prediction_rate_0})\n",
    "    wandb.log({\"dataset/prediction-rate-0\": fig_dataset_prediction_rate_0})\n",
    "    wandb.log({\"train/loss\": fig_train_loss_per_epoch})\n",
    "    # wandb.log({\"dataset/pull-plot-rate-0\": fig_dataset_pull_plot_rate_0})  # TODO: make it work with W&B \n",
    "    # wandb.log({\"dataset/pull-reduced-hist-rate-0\": fig_dataset_reduced_pull_hist_rate_0})  # TODO: same as above\n",
    "    # The last one doesn't work due to seaborn histplot and my vlines. It seems they can't convert matplotlib to pyplot correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd7b6b9",
   "metadata": {},
   "source": [
    "## Linear regression using `fe_cosmic`, to predict just `rate[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1691c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = stats.linregress(X_train[\"fe_cosmic\"], y_train[\"rate[0]\"])\n",
    "\n",
    "print(f\"Slope a: {result.slope}, Intercept b: {result.intercept},\\nR^2: {result.rvalue**2}, p-value: {result.pvalue}\")\n",
    "print(\"\\n\"+f\"std_a: {result.stderr}, std_b: {result.intercept_stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_linregress = X_test[\"fe_cosmic\"]*result.slope + result.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7311a261",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let's only look at `rate[0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argsort = np.argsort(X_val[\"unix_time\"])[::-1]\n",
    "# sorted_time_val = X_val[\"unix_time\"][argsort]\n",
    "# sorted_y_val_r0 = y_val.loc[:, \"rate[0]\"][argsort]\n",
    "sorted_val_r0_linregress = pred_linregress[argsort]\n",
    "\n",
    "plt.plot(sorted_time_val, sorted_y_val_r0, '-g', linewidth=0.1)\n",
    "plt.plot(sorted_time_val, sorted_val_r0_linregress, '-r', linewidth=0.1)\n",
    "plt.xlabel(\"Tunix [s]\")\n",
    "plt.ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "plt.title(\"Light curve of Rate[0]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6ebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_n = 1000\n",
    "high_n = 1500\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, (low_n, high_n) in enumerate([(1000, 1500), (2000, 2500),\n",
    "                                   (10000, 10500), (12000, 12500)]):\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_y_val_r0[low_n:high_n], '-g', linewidth=0.5)\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_val_r0_linregress[low_n:high_n], '-r', linewidth=0.5)\n",
    "    axs[i//2, i%2].set_xlabel(\"Tunix [s]\")\n",
    "    axs[i//2, i%2].set_ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "    axs[i//2, i%2].set_title(f\"Light curve Rate[0]: l={low_n}, h={high_n}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_n = 1000\n",
    "high_n = 1500\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for i, (low_n, high_n) in enumerate([(1000, 1200), (2000, 2200),\n",
    "                                   (10000, 10200), (12000, 12200)]):\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_y_val_r0[low_n:high_n], '-g', linewidth=0.5)\n",
    "    axs[i//2, i%2].plot(sorted_time_val[low_n:high_n], sorted_val_r0_linregress[low_n:high_n], '-r', linewidth=0.5)\n",
    "    axs[i//2, i%2].set_xlabel(\"Tunix [s]\")\n",
    "    axs[i//2, i%2].set_ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "    axs[i//2, i%2].set_title(f\"Light curve Rate[0]: l={low_n}, h={high_n}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a02b7",
   "metadata": {},
   "source": [
    "**TODO: measure the loss using linear regression instead of multi-layer perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a894dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(fitted_mlp.loss_), np.std(sorted_y_val_r0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5d3cbe",
   "metadata": {},
   "source": [
    "### Residual plot\n",
    "**Warning: we're gonna use the whole dataset, careful about data leakage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the whole X (fe_cosmic).. just to observe the residuals\n",
    "pred_X = X[\"fe_cosmic\"]*result.slope + result.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3e2d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X[\"unix_time\"], y.loc[:, \"rate[0]\"], '-g', linewidth=0.1)\n",
    "plt.plot(X[\"unix_time\"], pred_X, '-r', linewidth=0.1)\n",
    "plt.xlabel(\"Tunix [s]\")\n",
    "plt.ylabel(\"Avg Rate[0] [Hz]\")  # Nb. photons per second (averaged over each bin)\n",
    "plt.title(\"Light curve of Rate[0]: Prediction using whole dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "left, width = 0.1, 0.65\n",
    "bottom, height = 0.1, 0.65\n",
    "spacing = 0.03\n",
    "rect_residuals = [left, bottom, width, height]\n",
    "rect_histy = [left + width + spacing, bottom, 0.2, height]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_axes(rect_residuals)\n",
    "ax_histy = fig.add_axes(rect_histy, sharey=ax)\n",
    "\n",
    "ax.plot(X[\"unix_time\"], y.loc[:, \"rate[0]\"]-pred_X, '-r', linewidth=0.1)\n",
    "ax.set_xlabel(\"Tunix [s]\")\n",
    "ax.set_ylabel(\"Residual for Rate[0]\")  # Nb. photons per second (averaged over each bin)\n",
    "ax.set_title(\"Residual plot for Rate[0]\")\n",
    "\n",
    "\n",
    "\n",
    "ax_histy.tick_params(axis=\"y\", labelleft=False)\n",
    "ax_histy.set_title(\"Histogram\")\n",
    "ax_histy.set_xlabel(\"Count\")\n",
    "\n",
    "\n",
    "_ = ax_histy.hist(y.loc[:, \"rate[0]\"]-pred_X, bins=100, orientation='horizontal', alpha=0.5, zorder=np.inf)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d3cfe",
   "metadata": {},
   "source": [
    "**TODO: try compare via evaluation measures with NN**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
